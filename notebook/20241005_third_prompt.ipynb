{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third prompt\n",
    "\n",
    "長文は要約して出力した結果に対し、3つ目のプロンプトを追加し、コンテキストを元に文を作成できているかを判定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import datetime\n",
    "import tiktoken\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI APIキーを設定\n",
    "openai.api_key = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tatsu\\AppData\\Local\\Temp\\ipykernel_38828\\1591884372.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai.api_key)\n"
     ]
    }
   ],
   "source": [
    "# OpenAIの言語モデルを設定（ここではGPT-3を使用）\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回答ファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提供されたCSVファイルを読み込み\n",
    "query_df = pd.read_csv(\"../submit/20241005-0121_predictions.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = query_df.rename(columns={\"answer\": \"tmp_answer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'problem', 'full_answer', 'tmp_answer', 'evidence'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMを使って文章の修正を行う関数\n",
    "def check_answer(problem: str, tmp_answer: str, evidence: str) -> str:\n",
    "\n",
    "    check_prompt = PromptTemplate(\n",
    "        input_variables=[\"problem\", \"full_answer\", \"evidence\"],\n",
    "        template=\n",
    "            \"\"\"あなたは回答の確からしさを判定する優れたチェックシステムです。\n",
    "            問題に対し、仮の回答とその根拠が与えられています。\n",
    "            仮の回答が根拠から導き出せていない場合、「分かりません。」と回答してください。\n",
    "            それ以外の場合、仮の回答を1文字も変えずそのまま回答してください。\n",
    "\n",
    "                f\"問題: {problem}\\n\\n\"\n",
    "                f\"仮の回答: {tmp_answer}\\n\"\n",
    "                f\"根拠: {evidence}\\n\"\n",
    "            回答:\"\"\"\n",
    "    )\n",
    "    chain = check_prompt | llm\n",
    "\n",
    "    response = chain.invoke(\n",
    "        {\"problem\": problem, \"tmp_answer\": tmp_answer, \"evidence\": evidence}\n",
    "    )\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_summarize_answers(query_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # \"answer\" 列に対して処理を適用\n",
    "    query_df[\"answer\"] = query_df[\"tmp_answer\"]\n",
    "    for i in range(len(query_df.index)):\n",
    "        print(i)\n",
    "        query_df[\"answer\"][i] = check_answer(query_df[\"problem\"][i], query_df[\"tmp_answer\"][i], query_df[\"evidence\"][i])\n",
    "        print(query_df[\"answer\"][i])\n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = check_and_summarize_answers(query_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要な列（id, answer, evidence）をヘッダなしでCSVに書き出し\n",
    "query_df[['index', 'answer', 'evidence']].to_csv(\n",
    "    \"../submit/predictions.csv\",\n",
    "    index=False,\n",
    "    header=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup\n",
    "dt_now = datetime.datetime.now()\n",
    "ymdm = dt_now.strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "query_df[['index', 'problem', 'full_answer', 'answer', 'evidence']].to_csv(\n",
    "    f\"../submit/{ymdm}_predictions.csv\",\n",
    "    index=False,\n",
    "    header=True,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
